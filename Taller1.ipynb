{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio del Proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,0,0,0,0,0,0,3,1,1,0,2,0,1,0,1,1,0,1,1,1,1,0,5,1,0,0,0,0,0,1,0,1,1,0,2,1,1,9,2,6,0,1,0,1,0,1,0,1,0,0,0,8,3,1,1,1,1,0,0,1,1,0,4,0,2,1,7,5,0,0,0,0,2,3,1,0,0,1,0,0,0,0,2,0,3,1,1,0,0,0,0,0,1,1,1,7,0,0,0,1,1,4,0,1,5,1,1,0,0,1,1,0,0,2,1,0,1,0,2,1,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,4,1,0,0,1,1,0,2,2,0,1,1,0,0,1,0,0,0,3,0,0,2,0,0,1,1,7,2,1,1,2,1,0,1,3,0,14,1,1,2,1,0,1,0,0,0,1,0,0,1,1,1,1,5,1,0,0,1,0,0,0,0,1,0,0,0,2,1,7,0,1,1,1,4,1,2,1,0,0,5,0,2,5,1,3,0,0,0,1,0,2,2,1,0,0,1,0,0,5,1,0,0,0,0,1,0,1,1,1,0,3,2,2,0,1,5,0,0,0,0,0,0,0,0,2,1,1,0,1,1,0,0,1,0,0,0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5404ffba99de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrizTF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Authors: \n",
    "# Fernanda Otalora 865100607\n",
    "# Yurany Cortes    865100603        \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Abrir el archivo inicial y tomar el documento html\n",
    "archivo = open(\"archivosinicial/reut2-000.sgm\", \"r\")\n",
    "soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "archivo.close()\n",
    "\n",
    "#Tomar todos las etiquetas reuters\n",
    "documentos = []\n",
    "documentos = soup1.find_all('reuters')\n",
    "\n",
    "#leer archivo de stopwords, el cual tiene una sola linea con todas las palabras\n",
    "#separa por ';', las palabras se guardan en un array\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close()\n",
    "\n",
    "# Se crea el archivo para guardar los documentos.\n",
    "archivoProcesado = open(\"archivoprocesado/reut2-000.sgm\", \"w\")\n",
    "\n",
    "# Se lee cada documento tomando la etiqueta title y body,se concatena en una sola cadena quitando \n",
    "# saltos de linea, esa cadena se convierte a minuscula, se aplican patron para quitar caracteres \n",
    "# y stopwords, la linea depurada se guarda en el archivo.\n",
    "\n",
    "for i in range(len(documentos)):\n",
    "    try:          \n",
    "        cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "        cadena = cadena.lower()\n",
    "        cadena = cadena.replace(' reuter','') \n",
    "        cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)        \n",
    "        for j in range(len(words)):                                    \n",
    "            cadena = re.sub(\" \"+words[j]+\" \",\" \",cadena)\n",
    "        archivoProcesado.write(cadena+\"\\n\")                   \n",
    "    except:\n",
    "        pass        \n",
    "    \n",
    "archivoProcesado.close()\n",
    "\n",
    "#Se define un patron para hacer split en lo que no sea caracteres alfanumericos\n",
    "# y se obtiene el diccionario de palabras y se aplica la funcion set para quitar duplicados\n",
    "\n",
    "pattern = re.compile(r'\\W+')\n",
    "\n",
    "fileWords = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "dictionary = pattern.split(fileWords.read())\n",
    "dictionary = list(set(dictionary))\n",
    "fileWords.close()\n",
    "\n",
    "#Guardar el diccionar en un archivo.\n",
    "fileDictionary = open(\"archivoprocesado/dictionary.txt\", \"w\")\n",
    "fileDictionary.write(str(dictionary))\n",
    "fileDictionary.close()\n",
    "\n",
    "\n",
    "#Crear el Vector Space Model\n",
    "vectorSpace = open(\"archivoprocesado/matriz_tf2.txt\", \"w\")\n",
    "\n",
    "\n",
    "dictionary.remove(\"\")\n",
    "fileFinally = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "\n",
    "w=len(dictionary)\n",
    "h=len(fileFinally.readlines())\n",
    "\n",
    "n=0\n",
    "\n",
    "denominador=[0 for x in range(w)]\n",
    "linea=\"\"\n",
    "fileFinally = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "for lines in fileFinally.readlines(): \n",
    "    lineaAux=\"\"\n",
    "    for k in range(len(dictionary)):        \n",
    "        patron = re.compile(r''+dictionary[k]+'')        \n",
    "        count = len(patron.findall(lines))\n",
    "\n",
    "        lineaAux = lineaAux+\",\"+str(count)\n",
    "            \n",
    "        if count > 0:            \n",
    "            denominador[k]=denominador[k]+1\n",
    "        else:\n",
    "            denominador[k]=denominador[k]+0\n",
    "            \n",
    "    lineaAux = lineaAux.lstrip(\",\")\n",
    "    linea = linea+lineaAux +\"\\n\"\n",
    "    n=n+1    \n",
    "\n",
    "linea = linea.rstrip(\"\\n\")\n",
    "vectorSpace.write(linea)\n",
    "vectorSpace.close()\n",
    "    \n",
    "# Obtener matriz TF-IDF\n",
    "vectorSpace.close()\n",
    "matrizTF = open('archivoprocesado/matriz_tf2.txt').read()\n",
    "matrizTF = [item.split() for item in matrizTF.split('\\n')[:-1]]\n",
    "\n",
    "#Creamos matriz TF-IDF\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        print(matrizTF[i][j])\n",
    "        \n",
    "        \n",
    "fileFinally.close()        \n",
    "\n",
    "#fileFinally = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "#vectorSpace.close()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
