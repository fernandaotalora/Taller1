{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio del Proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Authors: Fernanda Otalora\n",
    "#         Yurany Cortes            \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Abrir el archivo inicial y tomar el documento html\n",
    "archivo = open(\"archivosinicial/reut2-000.sgm\", \"r\")\n",
    "soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "archivo.close()\n",
    "\n",
    "#Tomar todos las etiquetas reuters\n",
    "documentos = []\n",
    "documentos = soup1.find_all('reuters')\n",
    "\n",
    "#leer archivo de stopwords, el cual tiene una sola linea con todas las palabras\n",
    "#separa por ';', las palabras se guardan en un array\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close()\n",
    "\n",
    "# Se crea el archivo para guardar los documentos.\n",
    "archivoProcesado = open(\"archivoprocesado/reut2-000.sgm\", \"w\")\n",
    "\n",
    "# Se lee cada documento tomando la etiqueta title y body,se concatena en una sola cadena quitando \n",
    "# saltos de linea, esa cadena se convierte a minuscula, se aplican patron para quitar caracteres \n",
    "# y stopwords, la linea depurada se guarda en el archivo.\n",
    "\n",
    "for i in range(len(documentos)):\n",
    "    try:          \n",
    "        cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "        cadena = cadena.lower()\n",
    "        cadena = cadena.replace(' reuter','') \n",
    "        cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)        \n",
    "        for j in range(len(words)):                                    \n",
    "            cadena = re.sub(\" \"+words[j]+\" \",\" \",cadena)\n",
    "        archivoProcesado.write(cadena+\"\\n\")                   \n",
    "    except:\n",
    "        pass        \n",
    "    \n",
    "archivoProcesado.close()\n",
    "\n",
    "#Se define un patron para hacer split en lo que no sea caracteres alfanumericos\n",
    "# y se obtiene el diccionario de palabras y se aplica la funcion set para quitar duplicados\n",
    "\n",
    "pattern = re.compile(r'\\W+')\n",
    "\n",
    "fileWords = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "dictionary = pattern.split(fileWords.read())\n",
    "dictionary = list(set(dictionary))\n",
    "fileWords.close()\n",
    "\n",
    "#Guardar el diccionar en un archivo.\n",
    "fileDictionary = open(\"archivoprocesado/dictionary.txt\", \"w\")\n",
    "fileDictionary.write(str(dictionary))\n",
    "fileDictionary.close()\n",
    "\n",
    "\n",
    "#Crear el Vector Space Model\n",
    "vectorSpace = open(\"archivoprocesado/matriz_tf.txt\", \"w\")\n",
    "\n",
    "\n",
    "dictionary.remove(\"\")\n",
    "fileFinally = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "\n",
    "w=len(dictionary)\n",
    "h=len(fileFinally.readlines())\n",
    "matriz=[[0 for x in range(w)]for y in range(h)]\n",
    "n=0\n",
    "\n",
    "denominador=[0 for x in range(w)]\n",
    "\n",
    "fileFinally = open(\"archivoprocesado/reut2-000.sgm\", \"r\")\n",
    "for lines in fileFinally.readlines():            \n",
    "    for k in range(len(dictionary)):        \n",
    "        patron = re.compile(r''+dictionary[k]+'')        \n",
    "        count = len(patron.findall(lines))\n",
    "        matriz[n][k]= count        \n",
    "        if count > 0:            \n",
    "            denominador[k]=denominador[k]+1\n",
    "        else:\n",
    "            denominador[k]=denominador[k]+0\n",
    "         \n",
    "    n=n+1    \n",
    "        \n",
    "                       \n",
    "vectorSpace.write(str(matriz))\n",
    "\n",
    "#print(\"Tiempo de ejecucion: \" % (time.time()-start_time))        \n",
    "    \n",
    "    \n",
    "# Obtener matriz TF-IDF\n",
    "mtf=[]\n",
    "matrizTF = open(\"archivoprocesado/matriz_tf.txt\", \"r\")\n",
    "for i in matrizTF.read():\n",
    "    print(i)\n",
    "\n",
    "for i in range(len(mtf)):\n",
    "    #mtf[i].replace(\"[[\",\"\")\n",
    "    #mtf[i].replace(\"[\",\"\")\n",
    "    print(mtf[i])\n",
    "\n",
    "#Creamos matriz TF-IDF\n",
    "matrizTFIDF=[[0 for x in range(w)]for y in range(h)]\n",
    "            \n",
    "        \n",
    "fileFinally.close()        \n",
    "vectorSpace.close()\n",
    "fileDen.close()\n",
    "matrizTF.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
