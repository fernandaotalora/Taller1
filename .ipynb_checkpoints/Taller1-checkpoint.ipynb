{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 1 Buscador"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Authors: \n",
    "Fernanda Otalora 865100607\n",
    "Yurany Cortes    865100603     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procesan inicialmente todos los archivos que tienen las noticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup   \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Abrir el archivo inicial y tomar el documento html.\n",
    "\n",
    "archivo = open(\"archivosinicial/reut2-000.sgm\", \"r\")\n",
    "soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "archivo.close()\n",
    "\n",
    "documentos = []\n",
    "documentos = soup1.find_all('reuters')\n",
    "\n",
    "fileInitial = open(\"archivoprocesado/reut2-000.txt\", \"w\")\n",
    "fileRaw = open(\"archivoprocesado/raw.txt\", \"w\")\n",
    "\n",
    "for i in range(len(documentos)):\n",
    "        try:          \n",
    "            cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "            cadena = cadena.lower()\n",
    "            cadena = cadena.replace(' reuter','')           \n",
    "            fileInitial.write(cadena+\"\\n\") \n",
    "            cadena=documentos[i].title.string + \"@@,\"+ documentos[i].body.string +\"@@;\" \n",
    "            fileRaw.write(cadena+\"\\n\") \n",
    "        except:\n",
    "            pass   \n",
    "\n",
    "fileInitial.close()\n",
    "fileRaw.close()\n",
    "\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la funcion en la cual se aplican expresiones regulares para limpiar los documentos recibidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDocument(documentos,archivoProcesado):\n",
    "    for cadena in documentos.readlines():\n",
    "        try:                      \n",
    "            cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)        \n",
    "            for j in range(len(words)): \n",
    "                cadena = re.sub(\" \" + words[j]+\" \",\" \",cadena)\n",
    "                \n",
    "            archivoProcesado.write(cadena)                   \n",
    "        except:\n",
    "            pass        \n",
    "    \n",
    "\n",
    "archivoProcesado = open(\"archivoprocesado/fileDocumentos.txt\", \"w\")\n",
    "documentos =  open(\"archivosinicial/reut2-000.txt\", \"r\")\n",
    "processDocument(documentos,archivoProcesado)\n",
    "archivoProcesado.close()\n",
    "documentos.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el diccionario de los documentos recibidos.\n",
    "Se define un patron para hacer split en lo que no sea caracteres alfanumericos y se obtiene el diccionario de palabras y se aplica la funcion set para quitar duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def getDictionary(fileDoc,fileDic):\n",
    "    pattern = re.compile(r'\\W+')\n",
    "\n",
    "    fileWords = open(\"archivoprocesado/\"+fileDoc, \"r\")\n",
    "    dictionary = pattern.split(fileWords.read())\n",
    "    \n",
    "    dictionary = sorted(list(set(dictionary)))\n",
    "   \n",
    "    dictionary.remove(\"\")\n",
    "    fileWords.close()\n",
    "    \n",
    "    dicString = str(dictionary).lstrip(\"[\").rstrip(\"]\").replace(\", \",\",\")\n",
    "    dicArray  = dicString.split(\",\")\n",
    "    dicFinal = \"\"\n",
    "    \n",
    "    for i in range(len(dicArray)):\n",
    "        dicFinal = dicFinal+\",\"+dicArray[i].lstrip(\"'\").rstrip(\"'\")\n",
    "    \n",
    "    \n",
    "    #Guardar el diccionar en un archivo.\n",
    "    fileDictionary = open(\"archivoprocesado/\"+fileDic, \"w\")\n",
    "    fileDictionary.write(dicFinal.lstrip(\",\"))\n",
    "    fileDictionary.close()\n",
    "    \n",
    "getDictionary(\"fileDocumentos.txt\",\"dictionary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que crea la matrizTF y la guarda en un archivo, cuenta la cantidad de palabras en cada documento para crear el vector con los denominadores para obtener la matrizTFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF(fileMatriz,fileDic,fileDoc):\n",
    "    \n",
    "    dictionary  = open('archivoprocesado/'+fileDic).read()    \n",
    "    dictionary  = dictionary.split(\",\")\n",
    "    \n",
    "    #Crear el Vector Space Model\n",
    "    vectorSpace = open(\"archivoprocesado/\"+fileMatriz, \"w\")\n",
    "    fileFinally = open(\"archivoprocesado/\"+fileDoc, \"r\")\n",
    "\n",
    "    w=len(dictionary)\n",
    "    h=len(fileFinally.readlines())\n",
    "\n",
    "    n=0\n",
    "\n",
    "    denominador=[0 for x in range(w)]\n",
    "\n",
    "    linea=\"\"\n",
    "\n",
    "    fileFinally = open(\"archivoprocesado/\"+fileDoc, \"r\")\n",
    "    for lines in fileFinally.readlines(): \n",
    "        lineaAux=\"\"\n",
    "        for k in range(len(dictionary)):                                                 \n",
    "            patron = re.compile(r''+dictionary[k]+'')        \n",
    "            count = len(patron.findall(lines))\n",
    "\n",
    "            lineaAux = lineaAux+\",\"+str(count)\n",
    "\n",
    "            if count > 0:            \n",
    "                denominador[k]=denominador[k]+1\n",
    "            else:\n",
    "                denominador[k]=denominador[k]+0\n",
    "\n",
    "        lineaAux = lineaAux.lstrip(\",\")\n",
    "        linea = linea+lineaAux +\"\\n\"\n",
    "        n=n+1    \n",
    "\n",
    "    linea = linea.rstrip(\"\\n\")\n",
    "    vectorSpace.write(linea)\n",
    "    vectorSpace.close()\n",
    "    fileFinally.close()  \n",
    "    \n",
    "    fileDen = open(\"archivoprocesado/denominador.txt\", \"w\")\n",
    "    fileDen.write(str(denominador).lstrip(\"[\").rstrip(\"]\").replace(\", \",\",\"))\n",
    "    fileDen.close()\n",
    "    \n",
    "setMatrizTF(\"matriz_tf.txt\",\"dictionary.txt\",\"fileDocumentos.txt\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que crea la matrizTFIDF, aplicando la formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimilitudCoseno(VectorArchivo, vectorBusqueda):\n",
    "    x = np.array(VectorArchivo)\n",
    "    y = np.array(vectorBusqueda)\n",
    "    dot = np.dot(x,y)\n",
    "    x_modulus = np.sqrt((x*x).sum())\n",
    "    y_modulus = np.sqrt((y*y).sum())\n",
    "    similitud=0\n",
    "    if(x_modulus != 0 and y_modulus != 0 ):\n",
    "        similitud = dot / x_modulus / y_modulus\n",
    "    return similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'tf_idf': [[0, 1.3862943611198906], [5, 5.545177444479562], [6, 2.772588722239781], [7, 1.3862943611198906], [8, 2.772588722239781], [9, 1.3862943611198906], [14, 5.545177444479562], [15, 1.3862943611198906], [16, 6.931471805599453], [17, 6.931471805599453], [23, 2.772588722239781], [29, 1.3862943611198906], [31, 0.6931471805599453], [32, 0.6931471805599453], [33, 2.772588722239781], [34, 1.3862943611198906], [35, 1.3862943611198906], [37, 1.3862943611198906], [38, 1.3862943611198906], [40, 9.704060527839234], [42, 1.3862943611198906], [43, 0.6931471805599453], [44, 6.931471805599453], [46, 1.3862943611198906], [52, 2.772588722239781], [53, 0.6931471805599453], [54, 1.3862943611198906], [56, 0.6931471805599453], [58, 1.3862943611198906], [61, 6.931471805599453], [62, 1.3862943611198906], [63, 1.3862943611198906], [64, 1.3862943611198906], [65, 0.6931471805599453], [66, 1.3862943611198906], [69, 8.317766166719343], [70, 1.3862943611198906], [73, 1.3862943611198906], [75, 1.3862943611198906], [77, 4.027549014324932], [78, 2.772588722239781], [79, 1.3862943611198906], [80, 1.3862943611198906], [81, 1.3862943611198906], [82, 1.3862943611198906], [83, 1.3862943611198906], [87, 4.1588830833596715], [88, 1.3862943611198906], [89, 1.3862943611198906], [91, 1.3862943611198906], [92, 1.3862943611198906], [94, 0.6931471805599453], [95, 0.6931471805599453], [96, 1.3862943611198906], [97, 2.772588722239781], [98, 1.3862943611198906], [102, 2.0794415416798357], [104, 2.772588722239781], [107, 1.3862943611198906], [109, 1.3862943611198906], [110, 1.3862943611198906], [111, 1.3862943611198906], [113, 1.3862943611198906], [115, 1.3862943611198906], [118, 1.3862943611198906], [120, 1.3862943611198906], [124, 1.3862943611198906], [127, 1.3862943611198906], [128, 1.3862943611198906], [132, 0.6931471805599453], [135, 6.931471805599453], [136, 4.1588830833596715], [137, 2.772588722239781], [139, 1.3862943611198906], [142, 1.3862943611198906], [143, 1.3862943611198906], [145, 2.772588722239781], [147, 1.3862943611198906], [153, 0.6931471805599453], [156, 1.3862943611198906], [158, 5.545177444479562], [160, 0.6931471805599453], [161, 1.3862943611198906], [164, 1.3862943611198906], [165, 1.3862943611198906], [168, 1.3862943611198906], [169, 0.6931471805599453], [170, 1.3862943611198906], [173, 12.476649250079015], [174, 1.3862943611198906], [176, 1.3862943611198906], [177, 4.1588830833596715], [178, 0.6931471805599453], [181, 2.0794415416798357], [182, 2.772588722239781], [189, 2.772588722239781], [193, 4.1588830833596715], [195, 1.3862943611198906], [199, 0.6931471805599453], [200, 1.3862943611198906], [203, 1.3862943611198906], [204, 1.3862943611198906], [205, 1.3862943611198906], [206, 1.3862943611198906], [211, 1.3862943611198906], [213, 1.3862943611198906], [214, 1.3862943611198906], [215, 1.3862943611198906], [217, 2.772588722239781], [218, 1.3862943611198906], [219, 1.3862943611198906], [220, 1.4384103622589042], [221, 9.704060527839234], [222, 1.3862943611198906], [226, 0.6931471805599453], [227, 1.3862943611198906], [228, 6.931471805599453], [230, 2.772588722239781], [231, 2.772588722239781], [233, 1.3862943611198906], [235, 3.4657359027997265], [236, 2.772588722239781], [239, 1.3862943611198906], [240, 1.3862943611198906], [242, 0.6931471805599453], [246, 1.3862943611198906], [251, 2.772588722239781], [254, 1.3862943611198906], [255, 4.852030263919617], [256, 9.704060527839234], [257, 2.772588722239781], [258, 4.1588830833596715], [259, 1.3862943611198906], [262, 2.772588722239781], [265, 4.1588830833596715], [268, 2.772588722239781], [269, 1.3862943611198906], [270, 0.6931471805599453], [271, 1.3862943611198906], [275, 1.3862943611198906], [276, 11.090354888959125], [277, 1.3862943611198906]]}, {'id': 1, 'tf_idf': [[30, 1.3862943611198906], [36, 1.3862943611198906], [47, 1.3862943611198906], [108, 0.6931471805599453], [133, 1.3862943611198906], [157, 1.3862943611198906], [180, 4.1588830833596715], [183, 1.3862943611198906], [185, 1.3862943611198906], [186, 1.3862943611198906], [188, 1.3862943611198906], [208, 0.6931471805599453], [241, 5.545177444479562], [260, 1.3862943611198906], [263, 1.3862943611198906]]}, {'id': 2, 'tf_idf': [[3, 1.3862943611198906], [13, 1.3862943611198906], [18, 2.772588722239781], [19, 2.772588722239781], [21, 0.6931471805599453], [22, 0.6931471805599453], [27, 1.3862943611198906], [45, 4.1588830833596715], [49, 1.3862943611198906], [57, 1.3862943611198906], [59, 1.3862943611198906], [64, 0.6931471805599453], [71, 1.3862943611198906], [77, 0.5753641449035617], [85, 1.3862943611198906], [105, 0.6931471805599453], [106, 1.3862943611198906], [117, 1.3862943611198906], [119, 1.3862943611198906], [123, 1.3862943611198906], [138, 1.3862943611198906], [146, 1.3862943611198906], [172, 2.772588722239781], [191, 1.3862943611198906], [220, 0.5753641449035617], [253, 4.1588830833596715]]}, {'id': 3, 'tf_idf': [[1, 8.317766166719343], [2, 4.1588830833596715], [4, 2.772588722239781], [10, 1.3862943611198906], [11, 1.3862943611198906], [12, 1.3862943611198906], [19, 10.39720770839918], [20, 15.249237972318797], [21, 0.6931471805599453], [22, 1.3862943611198906], [24, 2.772588722239781], [25, 1.3862943611198906], [26, 2.772588722239781], [27, 0.6931471805599453], [28, 1.3862943611198906], [31, 2.772588722239781], [32, 1.3862943611198906], [39, 1.3862943611198906], [41, 2.772588722239781], [43, 0.6931471805599453], [48, 1.3862943611198906], [50, 1.3862943611198906], [51, 1.3862943611198906], [53, 0.6931471805599453], [55, 1.3862943611198906], [56, 0.6931471805599453], [60, 1.3862943611198906], [65, 0.6931471805599453], [67, 1.3862943611198906], [68, 6.931471805599453], [72, 1.3862943611198906], [74, 1.3862943611198906], [76, 1.3862943611198906], [77, 0.8630462173553426], [84, 1.3862943611198906], [86, 1.3862943611198906], [90, 1.3862943611198906], [93, 1.3862943611198906], [94, 1.3862943611198906], [95, 0.6931471805599453], [99, 1.3862943611198906], [100, 1.3862943611198906], [102, 0.6931471805599453], [103, 1.3862943611198906], [105, 0.6931471805599453], [108, 1.3862943611198906], [112, 1.3862943611198906], [114, 1.3862943611198906], [116, 1.3862943611198906], [121, 1.3862943611198906], [122, 1.3862943611198906], [125, 1.3862943611198906], [126, 1.3862943611198906], [129, 1.3862943611198906], [130, 1.3862943611198906], [131, 1.3862943611198906], [132, 0.6931471805599453], [134, 1.3862943611198906], [140, 1.3862943611198906], [141, 1.3862943611198906], [144, 1.3862943611198906], [148, 1.3862943611198906], [149, 5.545177444479562], [150, 4.1588830833596715], [151, 2.772588722239781], [152, 2.772588722239781], [153, 0.6931471805599453], [154, 1.3862943611198906], [155, 2.772588722239781], [159, 4.1588830833596715], [160, 0.6931471805599453], [162, 1.3862943611198906], [163, 1.3862943611198906], [166, 1.3862943611198906], [167, 1.3862943611198906], [169, 0.6931471805599453], [171, 1.3862943611198906], [175, 2.772588722239781], [178, 2.772588722239781], [179, 1.3862943611198906], [181, 1.3862943611198906], [184, 1.3862943611198906], [187, 1.3862943611198906], [190, 1.3862943611198906], [192, 1.3862943611198906], [194, 1.3862943611198906], [196, 1.3862943611198906], [197, 1.3862943611198906], [198, 1.3862943611198906], [199, 1.3862943611198906], [201, 1.3862943611198906], [202, 1.3862943611198906], [207, 2.772588722239781], [208, 0.6931471805599453], [209, 1.3862943611198906], [210, 1.3862943611198906], [212, 1.3862943611198906], [216, 1.3862943611198906], [220, 2.013774507162466], [223, 4.1588830833596715], [224, 1.3862943611198906], [225, 1.3862943611198906], [226, 0.6931471805599453], [229, 1.3862943611198906], [232, 1.3862943611198906], [234, 1.3862943611198906], [235, 0.6931471805599453], [237, 1.3862943611198906], [238, 1.3862943611198906], [242, 0.6931471805599453], [243, 1.3862943611198906], [244, 5.545177444479562], [245, 1.3862943611198906], [247, 1.3862943611198906], [248, 2.772588722239781], [249, 1.3862943611198906], [250, 1.3862943611198906], [252, 2.772588722239781], [255, 0.6931471805599453], [261, 1.3862943611198906], [264, 2.772588722239781], [266, 1.3862943611198906], [267, 1.3862943611198906], [268, 0.6931471805599453], [270, 0.6931471805599453], [272, 1.3862943611198906], [273, 1.3862943611198906], [274, 1.3862943611198906], [275, 0.6931471805599453]]}]\n",
      " ------ Tiempo de ejecucion 21.591472625732422 -----------\n"
     ]
    }
   ],
   "source": [
    "# Obtener matriz TF-IDF\n",
    "import math\n",
    "import time\n",
    "\n",
    "InvertedIndex = []\n",
    "TFIDFDb=[]\n",
    "def getMatrizTFIDF():\n",
    "    den= open(\"archivoprocesado/denominador.txt\", \"r\").read()\n",
    "    denominador = den.split(\",\")\n",
    "\n",
    "    matrizTF = open('archivoprocesado/matriz_tf.txt').read()\n",
    "    matrizTF = [item.split() for item in matrizTF.split('\\n')]\n",
    "\n",
    "    w=len(denominador)\n",
    "    h=len(matrizTF)\n",
    "\n",
    "    #Creamos matriz TF-IDF\n",
    "    fileMatriz= open(\"archivoprocesado/matriz_tfidf.txt\", \"w\")\n",
    "\n",
    "    doc = []\n",
    "    \n",
    "    logTerm=[]\n",
    "    \n",
    "    for i in range(len(matrizTF)):\n",
    "        fila = matrizTF[i]  \n",
    "        doc  = str(fila).lstrip(\"['\").rstrip(\"']\").split(\",\")\n",
    "        nq = []\n",
    "        \n",
    "        for j in range(len(doc)): \n",
    "\n",
    "            if i==0:\n",
    "                InvertedIndex.append([])\n",
    "                logTerm.append([])\n",
    "                logTerm[j]=math.log(h/int(denominador[j]))\n",
    "                tfidf= int(doc[j])*logTerm[j]\n",
    "                if(tfidf>0):\n",
    "                    nq.append([j,tfidf])\n",
    "            else:\n",
    "                tfidf = int(doc[j])*logTerm[j]\n",
    "                if(tfidf>0):\n",
    "                    nq.append([j,tfidf])\n",
    "            if(tfidf>0):\n",
    "                InvertedIndex[j].append(i)\n",
    "                \n",
    "        TFIDFDb.append( {\"id\":i,\"tf_idf\":nq} )\n",
    "    print(TFIDFDb)\n",
    "    filetfidf=open(\"archivoprocesado/matriz_tfidf.txt\", \"w\")\n",
    "    filetfidf.write(str(TFIDFDb))\n",
    "    print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))   \n",
    "   \n",
    "    fileRaw.close()\n",
    "    filetfidf.close()\n",
    "    #Guardar matriz TF - IDF            \n",
    "\n",
    "       \n",
    "\n",
    "getMatrizTFIDF()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para tomar la informacion ingresada en la caja de texto, crear el vector query y hacer similitud de coseno con la matriz tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Tiempo de ejecucion 63.12621188163757 -----------\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#Generar la ventana que recibe el texto del buscador\n",
    "vent = Tk()\n",
    "\n",
    "a = StringVar()\n",
    "\n",
    "def vectorSearch():\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    file  = open('archivoprocesado/fileSearch.txt').read()    \n",
    "    wordsSearch  = pattern.split(file)     \n",
    "     \n",
    "    dictionary  = open('archivoprocesado/dictionary.txt').read()    \n",
    "    dictionary  = dictionary.split(\",\")\n",
    "    \n",
    "    w=len(dictionary)\n",
    "    vector = []\n",
    "    vector = [0 for x in range(w)]\n",
    "    IdWords=[]\n",
    "    IdDocuments=[]\n",
    "    resultadosBusqueda=[]\n",
    "    for i in range(len(wordsSearch)):\n",
    "        try:\n",
    "            \n",
    "            ind = dictionary.index(wordsSearch[i])\n",
    "            IdWords.append(ind)\n",
    "            if(vector[ind]>0):\n",
    "                vector[ind] = vector[ind]+1\n",
    "            else:    \n",
    "                vector[ind] = 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if(len(IdWords)>0):\n",
    "        #Se busca con el indice invertido los documentos que tienen las palabras a buscar\n",
    "        for countWord in range(0,len(IdWords)):\n",
    "            for IdDocument in InvertedIndex[IdWords[countWord]]:\n",
    "                if(IdDocument not in IdDocuments):\n",
    "                    IdDocuments.append(IdDocument)\n",
    "    \n",
    "        countArchivos=0   \n",
    "        #Se recorre cada documento\n",
    "        for IdDocument in IdDocuments:\n",
    "                tf_idf =  [x for x in TFIDFDb if x['id'] == IdDocument][0]['tf_idf']\n",
    "                #armo la matriz TF-IDF\n",
    "                VectorArchivo = np.zeros(w)\n",
    "                for x in range(len(tf_idf)):\n",
    "                    VectorArchivo[tf_idf[x][0]]=tf_idf[x][1]\n",
    "                \n",
    "                resultadosBusqueda.append([])\n",
    "                #Calcula la similitud coseno de cada documento con el vector de busqueda\n",
    "                similitud = SimilitudCoseno(VectorArchivo, vector)\n",
    "\n",
    "                resultadosBusqueda[countArchivos].append(IdDocument)\n",
    "                resultadosBusqueda[countArchivos].append(similitud)\n",
    "                countArchivos+=1\n",
    "        resultadosBusqueda = sorted(resultadosBusqueda, key=lambda a_entry: a_entry[1],reverse=True) \n",
    "\n",
    "        #Se recuperan los documentos originales sin procesar\n",
    "        documentosRaw=open(\"archivoprocesado/raw.txt\", \"r\").read().split(\"@@;\")\n",
    "        clear_output()\n",
    "        #con los los resultados de la busqueda visualiza los documentos encontrados\n",
    "        for resultado in resultadosBusqueda:\n",
    "            print(resultado)\n",
    "            display(HTML('<h1>'+documentosRaw[resultado[0]].split(\"@@,\")[0]+'</h1>'))\n",
    "            display(HTML('<p>'+documentosRaw[resultado[0]].split(\"@@,\")[1]+'</p>'))\n",
    "    \n",
    "    \n",
    "    # vector tiene el query listo para aplicar similtud de coseno\n",
    "    #Leer la matriztf-idf para hacer similutd de coseno con el vector de query\n",
    "    \n",
    "    \n",
    "\n",
    "def valor():\n",
    "    a = entrada.get()\n",
    "    fileWords = open(\"archivoprocesado/buscador.txt\", \"w\")\n",
    "    a = a.lower()\n",
    "    fileWords.write(a)\n",
    "    fileWords.close()\n",
    "    \n",
    "    #Procesar las palabra ingresadas.\n",
    "    documentos=open(\"archivoprocesado/buscador.txt\", \"r\")\n",
    "    archivoProcesado = open(\"archivoprocesado/fileSearch.txt\", \"w\")\n",
    "    processDocument(documentos,archivoProcesado)\n",
    "    documentos.close()\n",
    "    archivoProcesado.close()\n",
    "    \n",
    "    vectorSearch()\n",
    "\n",
    "\n",
    "entrada = Entry(vent, width=30)\n",
    "entrada.grid(row=0, column=0)\n",
    "\n",
    "boton = Button(vent, text=\"Buscar\", command=valor)\n",
    "boton.grid(row=1, column=0)\n",
    "\n",
    "vent.mainloop()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
