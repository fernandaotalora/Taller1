{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 1 Buscador"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Authors: \n",
    "Fernanda Otalora 865100607\n",
    "Yurany Cortes    865100603     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procesan inicialmente todos los archivos que tienen las noticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup   \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Abrir el archivo inicial y tomar el documento html\n",
    "\n",
    "archivo = open(\"archivosinicial/reut2-000.sgm\", \"r\")\n",
    "soup1  = BeautifulSoup(archivo, 'html.parser')\n",
    "archivo.close()\n",
    "\n",
    "documentos = []\n",
    "documentos = soup1.find_all('reuters')\n",
    "\n",
    "fileInitial = open(\"archivoprocesado/reut2-000.txt\", \"w\")\n",
    "\n",
    "for i in range(len(documentos)):\n",
    "        try:          \n",
    "            cadena = documentos[i].title.string.replace('\\n',' ')+\" \"+documentos[i].body.string.replace('\\n',' ')\n",
    "            cadena = cadena.lower()\n",
    "            cadena = cadena.replace(' reuter','')           \n",
    "            fileInitial.write(cadena+\"\\n\")                   \n",
    "        except:\n",
    "            pass   \n",
    "\n",
    "fileInitial.close()\n",
    "\n",
    "\n",
    "words = []\n",
    "stopwords = open(\"archivosinicial/stopwords.txt\", \"r\")\n",
    "dato = stopwords.readline()\n",
    "words = dato.split(';')\n",
    "stopwords.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la funcion en la cual se aplican expresiones regulares para limpiar los documentos recibidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDocument(documentos,archivoProcesado):\n",
    "    for cadena in documentos.readlines():\n",
    "        try:                      \n",
    "            cadena = re.sub(r'<.*>|[0-9]|[,*$]|[.*$]|[-*$]|[(.*)$]|[/*$]|[\"*$]|[\\'][a-z|\\W]|[+*$]|[:*$]',\" \",cadena)        \n",
    "            for j in range(len(words)):                                    \n",
    "                cadena = re.sub(\" \"+words[j]+\" \",\" \",cadena)\n",
    "            archivoProcesado.write(cadena)                   \n",
    "        except:\n",
    "            pass        \n",
    "    \n",
    "\n",
    "archivoProcesado = open(\"archivoprocesado/fileDocumentos.txt\", \"w\")\n",
    "documentos =  open(\"archivosinicial/reut2-000.txt\", \"r\")\n",
    "processDocument(documentos,archivoProcesado)\n",
    "archivoProcesado.close()\n",
    "documentos.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el diccionario de los documentos recibidos.\n",
    "Se define un patron para hacer split en lo que no sea caracteres alfanumericos y se obtiene el diccionario de palabras y se aplica la funcion set para quitar duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def getDictionary(fileDoc,fileDic):\n",
    "    pattern = re.compile(r'\\W+')\n",
    "\n",
    "    fileWords = open(\"archivoprocesado/\"+fileDoc, \"r\")\n",
    "    dictionary = pattern.split(fileWords.read())\n",
    "    dictionary = list(set(dictionary))\n",
    "    dictionary.remove(\"\")\n",
    "    fileWords.close()\n",
    "    \n",
    "    dicString = str(dictionary).lstrip(\"[\").rstrip(\"]\").replace(\", \",\",\")\n",
    "    dicArray  = dicString.split(\",\")\n",
    "    dicFinal = \"\"\n",
    "    \n",
    "    for i in range(len(dicArray)):\n",
    "        dicFinal = dicFinal+\",\"+dicArray[i].lstrip(\"'\").rstrip(\"'\")\n",
    "    \n",
    "    \n",
    "    #Guardar el diccionar en un archivo.\n",
    "    fileDictionary = open(\"archivoprocesado/\"+fileDic, \"w\")\n",
    "    fileDictionary.write(dicFinal.lstrip(\",\"))\n",
    "    fileDictionary.close()\n",
    "    \n",
    "getDictionary(\"fileDocumentos.txt\",\"dictionary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que crea la matrizTF y la guarda en un archivo, cuenta la cantidad de palabras en cada documento para crear el vector con los denominadores para obtener la matrizTFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def setMatrizTF(fileMatriz,fileDic,fileDoc):\n",
    "    \n",
    "    dictionary  = open('archivoprocesado/'+fileDic).read()    \n",
    "    dictionary  = dictionary.split(\",\")\n",
    "    \n",
    "    #Crear el Vector Space Model\n",
    "    vectorSpace = open(\"archivoprocesado/\"+fileMatriz, \"w\")\n",
    "    fileFinally = open(\"archivoprocesado/\"+fileDoc, \"r\")\n",
    "\n",
    "    w=len(dictionary)\n",
    "    h=len(fileFinally.readlines())\n",
    "\n",
    "    n=0\n",
    "\n",
    "    denominador=[0 for x in range(w)]\n",
    "\n",
    "    linea=\"\"\n",
    "\n",
    "    fileFinally = open(\"archivoprocesado/\"+fileDoc, \"r\")\n",
    "    for lines in fileFinally.readlines(): \n",
    "        lineaAux=\"\"\n",
    "        for k in range(len(dictionary)):                                                 \n",
    "            patron = re.compile(r''+dictionary[k]+'')        \n",
    "            count = len(patron.findall(lines))\n",
    "\n",
    "            lineaAux = lineaAux+\",\"+str(count)\n",
    "\n",
    "            if count > 0:            \n",
    "                denominador[k]=denominador[k]+1\n",
    "            else:\n",
    "                denominador[k]=denominador[k]+0\n",
    "\n",
    "        lineaAux = lineaAux.lstrip(\",\")\n",
    "        linea = linea+lineaAux +\"\\n\"\n",
    "        n=n+1    \n",
    "\n",
    "    linea = linea.rstrip(\"\\n\")\n",
    "    vectorSpace.write(linea)\n",
    "    vectorSpace.close()\n",
    "    fileFinally.close()  \n",
    "    \n",
    "    fileDen = open(\"archivoprocesado/denominador.txt\", \"w\")\n",
    "    fileDen.write(str(denominador).lstrip(\"[\").rstrip(\"]\").replace(\", \",\",\"))\n",
    "    fileDen.close()\n",
    "    \n",
    "setMatrizTF(\"matriz_tf.txt\",\"dictionary.txt\",\"fileDocumentos.txt\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que crea la matrizTFIDF, aplicando la formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener matriz TF-IDF\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def getMatrizTFIDF():\n",
    "    den= open(\"archivoprocesado/denominador.txt\", \"r\").read()\n",
    "    denominador = den.split(\",\")\n",
    "\n",
    "    matrizTF = open('archivoprocesado/matriz_tf.txt').read()\n",
    "    matrizTF = [item.split() for item in matrizTF.split('\\n')]\n",
    "\n",
    "    w=len(denominador)\n",
    "    h=len(matrizTF)\n",
    "\n",
    "    matrizTFIDF = [[0 for x in range(w)] for y in range(h)]\n",
    "\n",
    "    #Creamos matriz TF-IDF\n",
    "    fileMatriz= open(\"archivoprocesado/matriz_tfidf.txt\", \"w\")\n",
    "\n",
    "    doc = []\n",
    "    for i in range(len(matrizTF)):\n",
    "        fila = matrizTF[i]     \n",
    "        doc  = str(fila).lstrip(\"['\").rstrip(\"']\").split(\",\")\n",
    "        for j in range(len(doc)):  \n",
    "            if(int(doc[j]) > 0):\n",
    "                matrizTFIDF[i][j] = int(doc[j])*math.log(h/int(denominador[j]))\n",
    "            else:    \n",
    "                matrizTFIDF[i][j] = 0\n",
    "\n",
    "\n",
    "    #Guardar matriz TF - IDF            \n",
    "\n",
    "    matrizFinal=[]            \n",
    "    matrizFinal =  str(matrizTFIDF).lstrip(\"[[\").rstrip(\"]]\").split(\"]\")\n",
    "    for m in range(len(matrizFinal)):\n",
    "        if((len(matrizFinal)-m)==1):\n",
    "            fileMatriz.write(matrizFinal[m].lstrip(\", [\").replace(\", \",\",\"))\n",
    "        else:\n",
    "            fileMatriz.write(matrizFinal[m].lstrip(\", [\").replace(\", \",\",\")+\"\\n\")\n",
    "\n",
    "    fileMatriz.close()    \n",
    "\n",
    "getMatrizTFIDF()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para tomar la informacion ingresada en la caja de texto, crear el vector query y hacer similitud de coseno con la matriz tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import re\n",
    "\n",
    "#Generar la ventana que recibe el texto del buscador\n",
    "vent = Tk()\n",
    "\n",
    "a = StringVar()\n",
    "\n",
    "def vectorSearch():\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    file  = open('archivoprocesado/fileSearch.txt').read()    \n",
    "    wordsSearch  = pattern.split(file)     \n",
    "    \n",
    "    dictionary  = open('archivoprocesado/dictionary.txt').read()    \n",
    "    dictionary  = dictionary.split(\",\")\n",
    "    \n",
    "    w=len(dictionary)\n",
    "    vector = []\n",
    "    vector = [0 for x in range(w)]\n",
    "    \n",
    "    for i in range(len(wordsSearch)):\n",
    "        try:\n",
    "            ind = dictionary.index(wordsSearch[i])\n",
    "            if(vector[ind]>0):\n",
    "                vector[ind] = vector[ind]+1\n",
    "            else:    \n",
    "                vector[ind] = 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # vector tiene el query listo para aplicar similtud de coseno\n",
    "    #Leer la matriztf-idf para hacer similutd de coseno con el vector de query\n",
    "    \n",
    "    matriztfidf = open(\"archivoprocesado/matriz_tfidf.txt\", \"r\")\n",
    "    for lines in matriztfidf.readlines():         \n",
    "        print(lines)\n",
    "\n",
    "def valor():\n",
    "    a = entrada.get()\n",
    "    fileWords = open(\"archivoprocesado/buscador.txt\", \"w\")\n",
    "    a = a.lower()\n",
    "    fileWords.write(a)\n",
    "    fileWords.close()\n",
    "    \n",
    "    #Procesar las palabra ingresadas.\n",
    "    documentos=open(\"archivoprocesado/buscador.txt\", \"r\")\n",
    "    archivoProcesado = open(\"archivoprocesado/fileSearch.txt\", \"w\")\n",
    "    processDocument(documentos,archivoProcesado)\n",
    "    documentos.close()\n",
    "    archivoProcesado.close()\n",
    "    \n",
    "    vectorSearch()\n",
    "\n",
    "\n",
    "entrada = Entry(vent, width=30)\n",
    "entrada.grid(row=0, column=0)\n",
    "\n",
    "boton = Button(vent, text=\"Buscar\", command=valor)\n",
    "boton.grid(row=1, column=0)\n",
    "\n",
    "vent.mainloop()\n",
    "\n",
    "\n",
    "print(\" ------ Tiempo de ejecucion %s -----------\" % (time.time()-start_time))     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
